{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3694ab5-51e2-4978-a7d9-2ee42c35937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import fluidsynth\n",
    "import glob\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2287bbe4-e9b5-41d1-8d81-cadfeac92bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Sampling rate for audio playback\n",
    "_SAMPLING_RATE = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5bdb79b-d08e-4398-8bd1-37cede1400a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Maestro = Midi Files \n",
    "data_dir = pathlib.Path('data/maestro-v3.0.0')\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "     'maestro-v3.0.0-midi.zip',\n",
    "      origin='https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip',\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data',\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fb9a7a-51f1-4139-99ee-c4550b8c7e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 1276\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob(str(data_dir/'**/*.mid*'))\n",
    "print('Number of files:', len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f2f07b2-3ba0-4655-a97a-8546ec296713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\maestro-v3.0.0\\2004\\MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_06_Track06_wav.midi\n"
     ]
    }
   ],
   "source": [
    "# Process a Midi file \n",
    "sample_file = filenames[1]\n",
    "print(sample_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23826176-7e5a-487d-bb32-5f6fa1d3cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_audio(pm: pretty_midi.PrettyMIDI, seconds=30):\n",
    "  waveform = pm.fluidsynth(fs=_SAMPLING_RATE)\n",
    "  # Take a sample of the generated waveform to mitigate kernel resets\n",
    "  waveform_short = waveform[:seconds*_SAMPLING_RATE]\n",
    "  return display.Audio(waveform_short, rate=_SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f046f79b-5825-40ab-a6b3-0192e5f028cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_to_notes(midi_file: str) -> pd.DataFrame:\n",
    "  pm = pretty_midi.PrettyMIDI(midi_file)\n",
    "  instrument = pm.instruments[0]\n",
    "  notes = collections.defaultdict(list)\n",
    "\n",
    "  # Sort the notes by start time\n",
    "  sorted_notes = sorted(instrument.notes, key=lambda note: note.start)\n",
    "  prev_start = sorted_notes[0].start\n",
    "\n",
    "  for note in sorted_notes:\n",
    "    start = note.start\n",
    "    end = note.end\n",
    "    notes['pitch'].append(note.pitch)\n",
    "    notes['start'].append(start)\n",
    "    notes['end'].append(end)\n",
    "    notes['step'].append(start - prev_start)\n",
    "    notes['duration'].append(end - start)\n",
    "    prev_start = start\n",
    "\n",
    "  return pd.DataFrame({name: np.array(value) for name, value in notes.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244fc431-8b12-4a13-99ec-aa53eeffa6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def notes_to_midi(\n",
    "  notes: pd.DataFrame,\n",
    "  out_file: str, \n",
    "  instrument_name: str,\n",
    "  velocity: int = 100,  # note loudness\n",
    ") -> pretty_midi.PrettyMIDI:\n",
    "\n",
    "  pm = pretty_midi.PrettyMIDI()\n",
    "  instrument = pretty_midi.Instrument(\n",
    "      program=pretty_midi.instrument_name_to_program(\n",
    "          instrument_name))\n",
    "\n",
    "  prev_start = 0\n",
    "  for i, note in notes.iterrows():\n",
    "    start = float(prev_start + note['step'])\n",
    "    end = float(start + note['duration'])\n",
    "    note = pretty_midi.Note(\n",
    "        velocity=velocity,\n",
    "        pitch=int(note['pitch']),\n",
    "        start=start,\n",
    "        end=end,\n",
    "    )\n",
    "    instrument.notes.append(note)\n",
    "    prev_start = start\n",
    "\n",
    "  pm.instruments.append(instrument)\n",
    "  pm.write(out_file)\n",
    "  return pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a101a63-7c71-4e46-9ebb-d6173b6022a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = 5\n",
    "all_notes = []\n",
    "for f in filenames[:num_files]:\n",
    "  notes = midi_to_notes(f)\n",
    "  all_notes.append(notes)\n",
    "\n",
    "all_notes = pd.concat(all_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a479132c-b36a-4f5b-bea2-83ea76c39e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notes parsed: 37241\n"
     ]
    }
   ],
   "source": [
    "n_notes = len(all_notes)\n",
    "print('Number of notes parsed:', n_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1ebafe-332d-45a5-99ed-04f8027f1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_order = ['pitch', 'step', 'duration']\n",
    "train_notes = np.stack([all_notes[key] for key in key_order], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26765716-d751-43f7-88bd-cb86fa29b1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorSpec(shape=(3,), dtype=tf.float64, name=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes_ds = tf.data.Dataset.from_tensor_slices(train_notes)\n",
    "notes_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "136bc7fe-0ae1-4b4b-9571-1e104e439a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(\n",
    "    dataset: tf.data.Dataset, \n",
    "    seq_length: int,\n",
    "    vocab_size = 128,\n",
    ") -> tf.data.Dataset:\n",
    "  \"\"\"Returns TF Dataset of sequence and label examples.\"\"\"\n",
    "  seq_length = seq_length+1\n",
    "\n",
    "  # Take 1 extra for the labels\n",
    "  windows = dataset.window(seq_length, shift=1, stride=1,\n",
    "                              drop_remainder=True)\n",
    "\n",
    "  # `flat_map` flattens the\" dataset of datasets\" into a dataset of tensors\n",
    "  flatten = lambda x: x.batch(seq_length, drop_remainder=True)\n",
    "  sequences = windows.flat_map(flatten)\n",
    "\n",
    "  # Normalize note pitch\n",
    "  def scale_pitch(x):\n",
    "    x = x/[vocab_size,1.0,1.0]\n",
    "    return x\n",
    "\n",
    "  # Split the labels\n",
    "  def split_labels(sequences):\n",
    "    inputs = sequences[:-1]\n",
    "    labels_dense = sequences[-1]\n",
    "    labels = {key:labels_dense[i] for i,key in enumerate(key_order)}\n",
    "\n",
    "    return scale_pitch(inputs), labels\n",
    "\n",
    "  return sequences.map(split_labels, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04dc72ac-3456-4d18-915c-b7b8a0a8dbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(25, 3), dtype=tf.float64, name=None),\n",
       " {'pitch': TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       "  'step': TensorSpec(shape=(), dtype=tf.float64, name=None),\n",
       "  'duration': TensorSpec(shape=(), dtype=tf.float64, name=None)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 25\n",
    "vocab_size = 128\n",
    "seq_ds = create_sequences(notes_ds, seq_length, vocab_size)\n",
    "seq_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cec5302-4dab-4c08-84bd-acb6a1b465b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "buffer_size = n_notes - seq_length  # the number of items in the dataset\n",
    "train_ds = (seq_ds\n",
    "            .shuffle(buffer_size)\n",
    "            .batch(batch_size, drop_remainder=True)\n",
    "            .cache()\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2caa97e-527a-4932-b24d-b0fc09322eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(64, 25, 3), dtype=tf.float64, name=None),\n",
       " {'pitch': TensorSpec(shape=(64,), dtype=tf.float64, name=None),\n",
       "  'step': TensorSpec(shape=(64,), dtype=tf.float64, name=None),\n",
       "  'duration': TensorSpec(shape=(64,), dtype=tf.float64, name=None)})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beeb5e52-7a4c-4e12-a227-887b08e989ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_with_positive_pressure(y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "  mse = (y_true - y_pred) ** 2\n",
    "  positive_pressure = 10 * tf.maximum(-y_pred, 0.0)\n",
    "  return tf.reduce_mean(mse + positive_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1598c7b-db1c-485f-b4a9-ca0ddc011bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    inputs = tf.keras.Input(input_shape)\n",
    "    x = tf.keras.layers.LSTM(hp.Int('units', min_value=64, max_value=256, step=32))(inputs)  # Hier variieren wir die Anzahl der LSTM-Einheiten\n",
    "\n",
    "    pitch_output = tf.keras.layers.Dense(128, name='pitch')(x)\n",
    "    step_output = tf.keras.layers.Dense(1, name='step')(x)\n",
    "    duration_output = tf.keras.layers.Dense(1, name='duration')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, [pitch_output, step_output, duration_output])\n",
    "\n",
    "    # Kompilieren des Modells mit der optimierten Lernrate\n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])  # Hier variieren wir die Lernrate\n",
    "        )\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e8a05ca-51b7-4853-a848-6b608381a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new version only\n",
    "#loss = {\n",
    "#    'pitch': SparseCategoricalCrossentropy(from_logits=True),\n",
    "#    'step': MeanSquaredError(),    \n",
    "#    'duration': MeanSquaredError()\n",
    "#}\n",
    "\n",
    "#input_shape = (seq_length, 3)\n",
    "#learning_rate = 0.005\n",
    "#optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "#model = build_model(input_shape, learning_rate)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55a1a29e-ebd9-42ca-9646-01cd6d8de079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ninput_shape = (seq_length, 3)\\nlearning_rate = 0.005\\n\\ninputs = tf.keras.Input(input_shape)\\nx = tf.keras.layers.LSTM(128)(inputs)\\n\\noutputs = {\\n  'pitch': tf.keras.layers.Dense(128, name='pitch')(x),\\n  'step': tf.keras.layers.Dense(1, name='step')(x),\\n  'duration': tf.keras.layers.Dense(1, name='duration')(x),\\n}\\n\\nmodel = tf.keras.Model(inputs, outputs)\\n\\nloss = {\\n      'pitch': tf.keras.losses.SparseCategoricalCrossentropy(\\n          from_logits=True),\\n      'step': mse_with_positive_pressure,\\n      'duration': mse_with_positive_pressure,\\n}\\n\\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\\n\\nmodel.compile(loss=loss, optimizer=optimizer)\\n\\nmodel.summary()\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# og version\n",
    "\"\"\"\n",
    "input_shape = (seq_length, 3)\n",
    "learning_rate = 0.005\n",
    "\n",
    "inputs = tf.keras.Input(input_shape)\n",
    "x = tf.keras.layers.LSTM(128)(inputs)\n",
    "\n",
    "outputs = {\n",
    "  'pitch': tf.keras.layers.Dense(128, name='pitch')(x),\n",
    "  'step': tf.keras.layers.Dense(1, name='step')(x),\n",
    "  'duration': tf.keras.layers.Dense(1, name='duration')(x),\n",
    "}\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "loss = {\n",
    "      'pitch': tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "          from_logits=True),\n",
    "      'step': mse_with_positive_pressure,\n",
    "      'duration': mse_with_positive_pressure,\n",
    "}\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0324143b-e137-45cd-8d07-e77104a2c00c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(train_ds, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m losses\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "losses = model.evaluate(train_ds, return_dict=True)\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ee27a69-7178-4410-8705-466a83945807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24 Complete [00h 02m 12s]\n",
      "loss: 3.3743269443511963\n",
      "\n",
      "Best loss So Far: 3.3743269443511963\n",
      "Total elapsed time: 00h 21m 43s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m final_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mbuild(best_hps)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Manuelles Training des finalen Modells ohne separate Validierungsdaten\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m final_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx_train\u001b[49m, y_train, epochs\u001b[38;5;241m=\u001b[39mbest_hps\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "#model.compile(\n",
    "#    loss=loss,\n",
    "#    loss_weights={\n",
    "#        'pitch': 0.05,\n",
    "#        'step': 1.0,\n",
    "#        'duration':1.0,\n",
    "#    },\n",
    "#    optimizer=optimizer,\n",
    "#)\n",
    "#old version compiled \n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='loss',\n",
    "    max_epochs=10,\n",
    "    hyperband_iterations=2\n",
    ")\n",
    "\n",
    "# Definition des Hyperparameter-Raums und Suche nach den besten Hyperparametern\n",
    "tuner.search(train_ds)\n",
    "\n",
    "# Erhalten der besten Hyperparametern\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Erstellen des finalen Modells mit den besten Hyperparametern\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60d954fb-3a63-4001-851d-5fad2eb77ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save('models/tuner_best_mode.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148c0dfc-e251-424a-86fa-50b4a45b8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./training_checkpoints/ckpt_{epoch}',\n",
    "        save_weights_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        restore_best_weights=True),\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c5315-20a9-4239-9d00-492768e7acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%time\n",
    "epochs = 10 # change back to 50\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8867e26-c93a-486f-a553-38787e0c87b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241m.\u001b[39mepoch, history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], label='total loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24439e1-c129-432c-81ca-a526f2e9b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# og Version \n",
    "\"\"\" def predict_next_note(\n",
    "    notes: np.ndarray, \n",
    "    model: tf.keras.Model, \n",
    "    temperature: float = 1.0) -> tuple[int, float, float]:\n",
    "  \"\"\"Generates a note as a tuple of (pitch, step, duration), using a trained sequence model.\"\"\"\n",
    "\n",
    "  assert temperature > 0\n",
    "\n",
    "  # Add batch dimension\n",
    "  inputs = tf.expand_dims(notes, 0)\n",
    "\n",
    "  predictions = model.predict(inputs)\n",
    "  pitch_logits = predictions['pitch']\n",
    "  step = predictions['step']\n",
    "  duration = predictions['duration']\n",
    "\n",
    "  pitch_logits /= temperature\n",
    "  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
    "  pitch = tf.squeeze(pitch, axis=-1)\n",
    "  duration = tf.squeeze(duration, axis=-1)\n",
    "  step = tf.squeeze(step, axis=-1)\n",
    "\n",
    "  # `step` and `duration` values should be non-negative\n",
    "  step = tf.maximum(0, step)\n",
    "  duration = tf.maximum(0, duration)\n",
    "\n",
    "  return int(pitch), float(step), float(duration)\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a189aef-a8d1-4439-9c46-ec4faf08bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new version\n",
    "def predict_next_note(\n",
    "    notes: np.ndarray, \n",
    "    model: tf.keras.Model, \n",
    "    temperature: float = 1.0) -> tuple[int, float, float]:\n",
    "  \"\"\"Generates a note as a tuple of (pitch, step, duration), using a trained sequence model.\"\"\"\n",
    "\n",
    "  assert temperature > 0\n",
    "\n",
    "  # Add batch dimension\n",
    "  inputs = tf.expand_dims(notes, 0)\n",
    "\n",
    "  predictions = model.predict(inputs)\n",
    "  pitch_logits = predictions[0]\n",
    "  step = predictions[1]\n",
    "  duration = predictions[2]\n",
    "\n",
    "  pitch_logits /= temperature\n",
    "  pitch = tf.random.categorical(pitch_logits, num_samples=1)\n",
    "  pitch = tf.squeeze(pitch, axis=-1)\n",
    "  duration = tf.squeeze(duration, axis=-1)\n",
    "  step = tf.squeeze(step, axis=-1)\n",
    "\n",
    "  # `step` and `duration` values should be non-negative\n",
    "  step = tf.maximum(0, step)\n",
    "  duration = tf.maximum(0, duration)\n",
    "\n",
    "  return int(pitch), float(step), float(duration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00317b-e4e5-4306-ad25-06715e1f1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and use it \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f42a1d-319d-4997-a11f-b82a40369d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = filenames[1]\n",
    "raw_notes = midi_to_notes(sample_file)\n",
    "\n",
    "pm = pretty_midi.PrettyMIDI(sample_file)\n",
    "\n",
    "instrument = pm.instruments[0]\n",
    "instrument_name = pretty_midi.program_to_instrument_name(instrument.program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0130af-bb43-40fb-810c-ca8ba2311379",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 2.0\n",
    "num_predictions = 120\n",
    "\n",
    "sample_notes = np.stack([raw_notes[key] for key in key_order], axis=1)\n",
    "\n",
    "# The initial sequence of notes; pitch is normalized similar to training\n",
    "# sequences\n",
    "input_notes = (\n",
    "    sample_notes[:seq_length] / np.array([vocab_size, 1, 1]))\n",
    "\n",
    "generated_notes = []\n",
    "prev_start = 0\n",
    "for _ in range(num_predictions):\n",
    "  pitch, step, duration = predict_next_note(input_notes, model, temperature)\n",
    "  start = prev_start + step\n",
    "  end = start + duration\n",
    "  input_note = (pitch, step, duration)\n",
    "  generated_notes.append((*input_note, start, end))\n",
    "  input_notes = np.delete(input_notes, 0, axis=0)\n",
    "  input_notes = np.append(input_notes, np.expand_dims(input_note, 0), axis=0)\n",
    "  prev_start = start\n",
    "\n",
    "generated_notes = pd.DataFrame(\n",
    "    generated_notes, columns=(*key_order, 'start', 'end'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e074a-3890-42d4-acbf-fbd7aa268288",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = 'output.mid'\n",
    "out_pm = notes_to_midi(\n",
    "    generated_notes, out_file=out_file, instrument_name=instrument_name)\n",
    "display_audio(out_pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227b28b2-d133-41c6-811b-09df24ee2797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: notwenig? \n",
    "#from google.colab import files\n",
    "#files.download(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db7c05-03ae-43e9-919d-2390168ea452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_piano_roll(generated_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42117937-2981-4228-9b69-1a405f135549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_distributions(generated_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c83735-bebd-4b21-942c-d1b4050d809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the alternatives to using RNNs for music generation is using GANs. \n",
    "#Rather than generating audio, a GAN-based approach can generate an entire sequence in parallel. \n",
    "# The Magenta team has done impressive work on this approach with GANSynth. \n",
    "#You can also find many wonderful music and art projects and open-source code on Magenta project website."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicKernel",
   "language": "python",
   "name": "musickernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
